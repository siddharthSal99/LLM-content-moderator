{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subreddits to explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit = 'r/explainlikeimfive'\n",
    "subreddits = ['r/explainlikeimfive', 'r/askscience', 'r/writingprompts', 'r/changemyview','r/outoftheloop','r/jokes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get auth headers from Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from config import CLIENT_ID, SECRET_KEY\n",
    "from config import OPENAI_API\n",
    "from config import reddit_auth_data as data\n",
    "\n",
    "auth = requests.auth.HTTPBasicAuth(CLIENT_ID, SECRET_KEY)\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'RedditAutomod/0.0.1'\n",
    "}\n",
    "\n",
    "res = requests.post('https://www.reddit.com/api/v1/access_token',\n",
    "                    auth=auth,\n",
    "                    data=data,\n",
    "                    headers=headers)\n",
    "TOKEN = res.json()['access_token']\n",
    "\n",
    "headers['Authorization'] = f'bearer {TOKEN}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate File Structure for Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "VALID = 'valid'\n",
    "INVALID = 'invalid'\n",
    "CWD = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sr in subreddits:\n",
    "    if not os.path.exists(os.path.join(os.getcwd(),sr)):\n",
    "        os.makedirs(os.path.join(CWD,sr))\n",
    "        os.makedirs(os.path.join(CWD,sr,VALID))\n",
    "        os.makedirs(os.path.join(CWD,sr,INVALID))\n",
    "\n",
    "    with open(os.path.join(CWD,sr,'rules.txt'),'+w') as file:\n",
    "        resp = requests.get(f'https://oauth.reddit.com/{sr}/about/rules', headers=headers).json()\n",
    "        # print(resp)\n",
    "        rulesPrompt = \"\"\n",
    "\n",
    "        for ix,el in enumerate(resp['rules']):\n",
    "            \n",
    "            ruleDesc = (el['description'])\n",
    "            singleRuleTemplate = f'Rule {ix}) {ruleDesc}\\n\\n'\n",
    "            rulesPrompt += singleRuleTemplate\n",
    "        file.write(rulesPrompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get good posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get good posts\n",
    "import time\n",
    "for sr in subreddits:\n",
    "    resp = requests.get(f'https://oauth.reddit.com/{sr}/hot?limit=100', headers=headers).json()\n",
    "    i = 0\n",
    "    for el in resp['data']['children']:\n",
    "        i += 1\n",
    "        post_details = f'Title: {el[\"data\"][\"title\"]} \\nPost Text: {el[\"data\"][\"selftext\"]}\\n'\n",
    "        with open(os.path.join(CWD,sr,VALID,f'good_{i}.txt'), '+w', encoding=\"utf-8\") as file:\n",
    "            file.write(post_details)\n",
    "\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Violating Post Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(openai_api_key=OPENAI_API)\n",
    "             \n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove dupes with chat memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"Title\", description=\"Reddit post title\"),\n",
    "    ResponseSchema(name=\"Post Text\", description=\"Reddit post main body of text\")\n",
    "]\n",
    "\n",
    "class Post(BaseModel):\n",
    "    title: str = Field(description=\"Reddit post title\")\n",
    "    post_text: str = Field(description=\"Reddit post main body of text\")\n",
    "\n",
    "output_parser = PydanticOutputParser(pydantic_object=Post)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "rule_number = 2\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are generating posts for the subreddit {subreddit}. Generate a post that would violate this rule in the subreddit community guidelines: {rule}. \n",
    "    \\n{format_instructions}\n",
    "    \\n {human_input}\"\"\",\n",
    "    input_variables=[\"rule\",\"human_input\", \"subreddit\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key = \"chat_history\",input_key=\"human_input\")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt, output_parser=StrOutputParser())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Rule 0) * 100 words minimum for stories, 30 for poems but include [Poem]\\n* Newly written by you for the prompt (no AI)\\n* Plagiarism will result in a ban\\n* No joke, copypasta, or AI-generated responses\\n* For off topic/clarification, reply to the sticky comment\\n\\n', 'Rule 1) * No explicit sexual responses / erotica\\n* Includes, but is not limited to, forms of pedophilia, bestiality, incest, rape, suicide, violence against children, and explicit torture\\n* Avoid racism and detailed uses of suicide, mental health stereotypes, and political debate\\n* Use your best judgment, but mods have final say\\n\\n', \"Rule 2) * Users are held to a higher standard here. Think before posting\\n* We are here to encourage writing\\n* Understand that people here are at all different levels:\\n * New writers\\n * Experienced writers\\n * Professional writers\\n * Users who are just learning English\\n* Typos and grammatical errors are possible.  Be nice if you point it out\\n* Feedback and critiques are encouraged, but just saying something's bad is not helpful at all and will be considered trolling\\n\\n\", 'Rule 3) All submissions must start with *one* capitalized **tag** in **square brackets**:\\n\\n* [WP] - **Writing Prompt**\\n* [SP] - **Simple Prompt**\\n* [EU] - **Established Universe**\\n* [CW] - **Constrained Writing**\\n* [TT]  - **Theme Thursday**\\n* [MP] - **Media Prompt**\\n* [IP] - **Image Prompt**\\n* [RF] - **Reality Fiction**\\n* [PM] - **Prompt Me**\\n* [PI] - **Prompt Inspired**\\n* [OT] - **Off Topic**\\n\\n[**More &gt;&gt;**](/r/WritingPrompts/wiki/how_to_tag_prompts)\\n\\n', \"Rule 4) * Search before submitting! (Popular ideas can cause floods)\\n* Reposts are allowed, given time (around two weeks)\\n* Don't take a recent prompt and change/invert small details\\n\\n\", \"Rule 5) * Prompt in the title and only use text for commentary or links for [IP]s and [MP]s.  Avoid [too many details](http://goo.gl/6v3rGd)\\n* No requesting writing or editing services, or homework help\\n* Don't post ads without getting permission in modmail first\\n* Don't ask writers to pick titles or content from another sub or site\\n* Prompts should not call for using autocorrect, autocomplete, or only emojis\\n\\n\", 'Rule 6) * Avoid real world drama (including politics, recent tragedies)\\n* Inspire an effort, avoid simple questions, \"write anything\", or fill-in-the-blanks\\n* Don\\'t ask for preexisting content (prompts are meant for new writing)\\n* No explicitly sexual themes, hate speech, or other harmful content (including hate speech, racism, politics, necrophila, pedophila, bestiality, incest, torture, rape, violence against children, suicide, and mental health stereotypes)\\n* No troll, poop, or meme-based prompts\\n\\n', \"Rule 7) * Wait until prompt is 24 hours old before linking from other subs to avoid vote manipulation and/or brigading (Text posts OK with no link and links *from* a story *to* another sub are fine)\\n* Don't spam the subreddit with links to crowdfunding sites like Patreon and Paypal.  Authors are free to link to those from their personal subreddits\\n* Any recording or use of other people's stories must follow the [guidance in the FAQ](https://www.reddit.com/r/WritingPrompts/wiki/faq)\\n\\n\"]\n"
     ]
    }
   ],
   "source": [
    "subreddit = 'r/writingprompts'\n",
    "# Get Rules\n",
    "resp = requests.get(f'https://oauth.reddit.com/{subreddit}/about/rules', headers=headers).json()\n",
    "# print(resp)\n",
    "rulesPrompt = []\n",
    "\n",
    "for ix,el in enumerate(resp['rules']):\n",
    "    \n",
    "    ruleDesc = (el['description'])\n",
    "    singleRuleTemplate = f'Rule {ix}) {ruleDesc}\\n\\n'\n",
    "    rulesPrompt.append(singleRuleTemplate)\n",
    "print(rulesPrompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Breaking the Rules!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:02<00:23,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: What's Going On??\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:04<00:18,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Breaking the Rules??!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:07<00:16,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: !!!Breaking News!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:09<00:13,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Weird and Wacky News From Around the World!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:11<00:11,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Breaking the Rules: Titles Must Be Unbiased!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:14<00:10,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Breaking Rule 0: Unbiased and Coherent Titles??\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:17<00:07,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Breaking News: Unbiased and Incoherent!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:19<00:04,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: ???!?!?!?!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:21<00:02,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Breaking the Rules Here!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:23<00:00,  2.38s/it]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Help! I'm Out of the Loop!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:02<00:20,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Question about something\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:04<00:18,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Help me out!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:06<00:15,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Help! I'm Out of the Loop!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:09<00:13,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Help me out of the loop!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:11<00:11,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Help me understand this!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:14<00:09,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Help! I'm Out of the Loop!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:16<00:07,  2.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: What's going on?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:18<00:04,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Help! I'm Out Of the Loop!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:21<00:02,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: What's going on?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:23<00:00,  2.32s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "for rule_number in [0,5, 6]:\n",
    "    for i in tqdm(range(10)):\n",
    "        output = chain.predict(human_input= \"\", rule=rulesPrompt[rule_number], subreddit=subreddit)\n",
    "        op = output_parser.parse(output)\n",
    "        # op = chain.predict(subreddit=subreddit,rules=rulesPrompt,text=\"\", rule_number=2)\n",
    "        with open(os.path.join(os.getcwd(), subreddit, INVALID, f'rule_{rule_number}_{i}.txt'),'+w') as file:\n",
    "            print(f'Title: {op.title}')\n",
    "            file.write(f'Title: {op.title}\\nPost Text:{op.post_text}')\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"title\": {\"title\": \"Title\", \"description\": \"Reddit post title\", \"type\": \"string\"}, \"post_text\": {\"title\": \"Post Text\", \"description\": \"Reddit post main body of text\", \"type\": \"string\"}}, \"required\": [\"title\", \"post_text\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# op = output_parser.parse(output)\n",
    "# output\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutputParserException",
     "evalue": "Got invalid JSON object. Error: Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\output_parsers\\json.py:163\u001b[0m, in \u001b[0;36mparse_and_check_json_markdown\u001b[1;34m(text, expected_keys)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     json_obj \u001b[39m=\u001b[39m parse_json_markdown(text)\n\u001b[0;32m    164\u001b[0m \u001b[39mexcept\u001b[39;00m json\u001b[39m.\u001b[39mJSONDecodeError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\output_parsers\\json.py:145\u001b[0m, in \u001b[0;36mparse_json_markdown\u001b[1;34m(json_string, parser)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[39m# Parse the JSON string into a Python dictionary\u001b[39;00m\n\u001b[1;32m--> 145\u001b[0m parsed \u001b[39m=\u001b[39m parser(json_str)\n\u001b[0;32m    147\u001b[0m \u001b[39mreturn\u001b[39;00m parsed\n",
      "File \u001b[1;32mc:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[0;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[39mcontaining a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[0;32m    338\u001b[0m end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n",
      "File \u001b[1;32mc:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    356\u001b[0m \u001b[39mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\siddh\\Documents\\Projects\\Masters\\UIUC\\CS598-KSA\\LLM-content-moderator\\generate_posts.ipynb Cell 15\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/siddh/Documents/Projects/Masters/UIUC/CS598-KSA/LLM-content-moderator/generate_posts.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m chat_prompt \u001b[39m=\u001b[39m ChatPromptTemplate\u001b[39m.\u001b[39mfrom_messages([\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/siddh/Documents/Projects/Masters/UIUC/CS598-KSA/LLM-content-moderator/generate_posts.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39msystem\u001b[39m\u001b[39m\"\u001b[39m, template),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/siddh/Documents/Projects/Masters/UIUC/CS598-KSA/LLM-content-moderator/generate_posts.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m\"\u001b[39m, human_template),\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/siddh/Documents/Projects/Masters/UIUC/CS598-KSA/LLM-content-moderator/generate_posts.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m ])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/siddh/Documents/Projects/Masters/UIUC/CS598-KSA/LLM-content-moderator/generate_posts.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m chain \u001b[39m=\u001b[39m LLMChain(llm\u001b[39m=\u001b[39mllm, prompt\u001b[39m=\u001b[39mchat_prompt, output_parser\u001b[39m=\u001b[39moutput_parser)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/siddh/Documents/Projects/Masters/UIUC/CS598-KSA/LLM-content-moderator/generate_posts.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m out \u001b[39m=\u001b[39m chain\u001b[39m.\u001b[39;49mrun(subreddit\u001b[39m=\u001b[39;49msubreddit,rules\u001b[39m=\u001b[39;49mrulesPrompt,text\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mCreate a post for this subreddit that would violate rule 4\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/siddh/Documents/Projects/Masters/UIUC/CS598-KSA/LLM-content-moderator/generate_posts.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(out)\n",
      "File \u001b[1;32mc:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\chains\\base.py:508\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[0;32m    503\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(args[\u001b[39m0\u001b[39m], callbacks\u001b[39m=\u001b[39mcallbacks, tags\u001b[39m=\u001b[39mtags, metadata\u001b[39m=\u001b[39mmetadata)[\n\u001b[0;32m    504\u001b[0m         _output_key\n\u001b[0;32m    505\u001b[0m     ]\n\u001b[0;32m    507\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[1;32m--> 508\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(kwargs, callbacks\u001b[39m=\u001b[39;49mcallbacks, tags\u001b[39m=\u001b[39;49mtags, metadata\u001b[39m=\u001b[39;49mmetadata)[\n\u001b[0;32m    509\u001b[0m         _output_key\n\u001b[0;32m    510\u001b[0m     ]\n\u001b[0;32m    512\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m    513\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    514\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`run` supported with either positional arguments or keyword arguments,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    515\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m but none were provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    516\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\chains\\base.py:308\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    307\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 308\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    309\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    310\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[0;32m    311\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    312\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\chains\\base.py:302\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[0;32m    295\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    296\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[0;32m    297\u001b[0m     inputs,\n\u001b[0;32m    298\u001b[0m     name\u001b[39m=\u001b[39mrun_name,\n\u001b[0;32m    299\u001b[0m )\n\u001b[0;32m    300\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    301\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 302\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    303\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    304\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[0;32m    305\u001b[0m     )\n\u001b[0;32m    306\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    307\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32mc:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\chains\\llm.py:94\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call\u001b[39m(\n\u001b[0;32m     89\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     90\u001b[0m     inputs: Dict[\u001b[39mstr\u001b[39m, Any],\n\u001b[0;32m     91\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     92\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m     93\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate([inputs], run_manager\u001b[39m=\u001b[39mrun_manager)\n\u001b[1;32m---> 94\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcreate_outputs(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\chains\\llm.py:222\u001b[0m, in \u001b[0;36mLLMChain.create_outputs\u001b[1;34m(self, llm_result)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_outputs\u001b[39m(\u001b[39mself\u001b[39m, llm_result: LLMResult) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Dict[\u001b[39mstr\u001b[39m, Any]]:\n\u001b[0;32m    221\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Create outputs from response.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m     result \u001b[39m=\u001b[39m [\n\u001b[0;32m    223\u001b[0m         \u001b[39m# Get the text of the top generated string.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m         {\n\u001b[0;32m    225\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_parser\u001b[39m.\u001b[39mparse_result(generation),\n\u001b[0;32m    226\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mfull_generation\u001b[39m\u001b[39m\"\u001b[39m: generation,\n\u001b[0;32m    227\u001b[0m         }\n\u001b[0;32m    228\u001b[0m         \u001b[39mfor\u001b[39;00m generation \u001b[39min\u001b[39;00m llm_result\u001b[39m.\u001b[39mgenerations\n\u001b[0;32m    229\u001b[0m     ]\n\u001b[0;32m    230\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_final_only:\n\u001b[0;32m    231\u001b[0m         result \u001b[39m=\u001b[39m [{\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key: r[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key]} \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m result]\n",
      "File \u001b[1;32mc:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\chains\\llm.py:225\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_outputs\u001b[39m(\u001b[39mself\u001b[39m, llm_result: LLMResult) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Dict[\u001b[39mstr\u001b[39m, Any]]:\n\u001b[0;32m    221\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Create outputs from response.\"\"\"\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     result \u001b[39m=\u001b[39m [\n\u001b[0;32m    223\u001b[0m         \u001b[39m# Get the text of the top generated string.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m         {\n\u001b[1;32m--> 225\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_parser\u001b[39m.\u001b[39;49mparse_result(generation),\n\u001b[0;32m    226\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mfull_generation\u001b[39m\u001b[39m\"\u001b[39m: generation,\n\u001b[0;32m    227\u001b[0m         }\n\u001b[0;32m    228\u001b[0m         \u001b[39mfor\u001b[39;00m generation \u001b[39min\u001b[39;00m llm_result\u001b[39m.\u001b[39mgenerations\n\u001b[0;32m    229\u001b[0m     ]\n\u001b[0;32m    230\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_final_only:\n\u001b[0;32m    231\u001b[0m         result \u001b[39m=\u001b[39m [{\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key: r[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_key]} \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m result]\n",
      "File \u001b[1;32mc:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\schema\\output_parser.py:226\u001b[0m, in \u001b[0;36mBaseOutputParser.parse_result\u001b[1;34m(self, result, partial)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse_result\u001b[39m(\u001b[39mself\u001b[39m, result: List[Generation], \u001b[39m*\u001b[39m, partial: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[0;32m    214\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Parse a list of candidate model Generations into a specific format.\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \n\u001b[0;32m    216\u001b[0m \u001b[39m    The return value is parsed from only the first Generation in the result, which\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[39m        Structured output.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 226\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse(result[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mtext)\n",
      "File \u001b[1;32mc:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\output_parsers\\structured.py:95\u001b[0m, in \u001b[0;36mStructuredOutputParser.parse\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse\u001b[39m(\u001b[39mself\u001b[39m, text: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m     94\u001b[0m     expected_keys \u001b[39m=\u001b[39m [rs\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m rs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresponse_schemas]\n\u001b[1;32m---> 95\u001b[0m     \u001b[39mreturn\u001b[39;00m parse_and_check_json_markdown(text, expected_keys)\n",
      "File \u001b[1;32mc:\\Users\\siddh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\output_parsers\\json.py:165\u001b[0m, in \u001b[0;36mparse_and_check_json_markdown\u001b[1;34m(text, expected_keys)\u001b[0m\n\u001b[0;32m    163\u001b[0m     json_obj \u001b[39m=\u001b[39m parse_json_markdown(text)\n\u001b[0;32m    164\u001b[0m \u001b[39mexcept\u001b[39;00m json\u001b[39m.\u001b[39mJSONDecodeError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 165\u001b[0m     \u001b[39mraise\u001b[39;00m OutputParserException(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot invalid JSON object. Error: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    166\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m expected_keys:\n\u001b[0;32m    167\u001b[0m     \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m json_obj:\n",
      "\u001b[1;31mOutputParserException\u001b[0m: Got invalid JSON object. Error: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limitations:\n",
    "would need to recursively follow links and only operate on text of webpages - parsing webpages is not simple. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
